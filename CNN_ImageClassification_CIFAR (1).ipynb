{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "au0VfLAsj1OI"
   },
   "source": [
    "# Image Classification with Convolutional Neural Networks, CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zFlhvrEuj1OL"
   },
   "source": [
    "### Make the notebook compatible with both Python 2 and 3\n",
    "\n",
    "http://python-future.org/compatible_idioms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "dAYhybfWj1ON"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7081,
     "status": "ok",
     "timestamp": 1521468659136,
     "user": {
      "displayName": "Ankur Kothari",
      "photoUrl": "//lh5.googleusercontent.com/-Lskyz0lrQRk/AAAAAAAAAAI/AAAAAAAACaI/etLcVFjKyHk/s50-c-k-no/photo.jpg",
      "userId": "111542912336803354359"
     },
     "user_tz": 240
    },
    "id": "YtHsGhpPj1OS",
    "outputId": "cb68f63e-76a1-4ef9-9117-a44f9daaa77c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqOj6Lt4j1Oc"
   },
   "source": [
    "### Plot graphs inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "_-ysJ4rIj1Od"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1521468659775,
     "user": {
      "displayName": "Ankur Kothari",
      "photoUrl": "//lh5.googleusercontent.com/-Lskyz0lrQRk/AAAAAAAAAAI/AAAAAAAACaI/etLcVFjKyHk/s50-c-k-no/photo.jpg",
      "userId": "111542912336803354359"
     },
     "user_tz": 240
    },
    "id": "87cbAwvDj1Oo",
    "outputId": "06071598-a8f0-4eee-878b-ca5f439f8a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0-dev20180115\n",
      "1.14.0\n",
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2pZcITYj1Ow"
   },
   "source": [
    "### Download the CIFAR-10 dataset\n",
    "\n",
    "More information on the dataset can be found here: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "The file is 17MB so this might take a while\n",
    "\n",
    "The dataset is broken into batches to prevent your machine from running out of memory. The CIFAR-10 dataset consists of 5 batches, named data_batch_1, data_batch_2, etc.. Each batch contains the labels and images that are one of the following:\n",
    "\n",
    "* 0 - airplane\n",
    "* 1 - automobile\n",
    "* 2 - bird\n",
    "* 3 - cat\n",
    "* 4 - deer\n",
    "* 5 - dog\n",
    "* 6 - frog\n",
    "* 7 - horse\n",
    "* 8 - ship\n",
    "* 9 - truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eIn5GG-wj1Oy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lr_HO07Rj1O3"
   },
   "source": [
    "### Untar and unzip the files\n",
    "\n",
    "* The extracted files (one for each batch) are placed in the folder *cifar-10-batches-py/* under your current working directory \n",
    "* Each file is named *data_batch_1, data_batch_2* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "XzNDb5gxj1O4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69jWowltj1O9"
   },
   "source": [
    "### Load and pre-process files\n",
    "\n",
    "* Access the image and the labels from a single batch specified by id (1-5)\n",
    "* Reshape the images, the images are **fed to the convolutional layer as a 4-D tensor**, notice that the reshape has the channels at axis index 1 \n",
    "* Transpose the axes of the reshaped image to be in this form: *[batch_size, height, width, channels]*, **channels should be the last axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 162
      },
      {
       "item_id": 200
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 53741,
     "status": "ok",
     "timestamp": 1521468721564,
     "user": {
      "displayName": "Ankur Kothari",
      "photoUrl": "//lh5.googleusercontent.com/-Lskyz0lrQRk/AAAAAAAAAAI/AAAAAAAACaI/etLcVFjKyHk/s50-c-k-no/photo.jpg",
      "userId": "111542912336803354359"
     },
     "user_tz": 240
    },
    "id": "77Uv4qJoj1O-",
    "outputId": "a3751801-83a3-4a5a-bd7d-0320f02ab59b"
   },
   "outputs": [],
   "source": [
    "(features, labels), (X_test_orig, Y_test_orig) = cifar10.load_data()\n",
    "features = features/255 - 0.5\n",
    "labels = labels.flatten()\n",
    "\n",
    "test_images = X_test_orig/255 - 0.5\n",
    "test_labels = Y_test_orig.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bzxNGWUmj1PC"
   },
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1521406508131,
     "user": {
      "displayName": "Ankur Kothari",
      "photoUrl": "//lh5.googleusercontent.com/-Lskyz0lrQRk/AAAAAAAAAAI/AAAAAAAACaI/etLcVFjKyHk/s50-c-k-no/photo.jpg",
      "userId": "111542912336803354359"
     },
     "user_tz": 240
    },
    "id": "BI5Sgy43j1PE",
    "outputId": "ed6b1816-08b4-440d-a326-dfff099cfe17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1521406508573,
     "user": {
      "displayName": "Ankur Kothari",
      "photoUrl": "//lh5.googleusercontent.com/-Lskyz0lrQRk/AAAAAAAAAAI/AAAAAAAACaI/etLcVFjKyHk/s50-c-k-no/photo.jpg",
      "userId": "111542912336803354359"
     },
     "user_tz": 240
    },
    "id": "2RshBXh0j1PK",
    "outputId": "b0b85d63-384d-4125-961b-8eefc2c6375d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1521406509214,
     "user": {
      "displayName": "Ankur Kothari",
      "photoUrl": "//lh5.googleusercontent.com/-Lskyz0lrQRk/AAAAAAAAAAI/AAAAAAAACaI/etLcVFjKyHk/s50-c-k-no/photo.jpg",
      "userId": "111542912336803354359"
     },
     "user_tz": 240
    },
    "id": "mTi3RrG8j1PP",
    "outputId": "37747ecf-731e-4eff-8134-4a7a45c36d89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.flatten()\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KiLXdBm4j1PX"
   },
   "source": [
    "### Helper functions to display images as well as labels\n",
    "\n",
    "* Map the integer labels to the actual labels for display\n",
    "* Plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "8VBdWGBbj1PX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "iHwGIaf4j1Pc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lepd7U7qj1Pi"
   },
   "source": [
    "### Access the *training* data and the corresponding labels\n",
    "\n",
    "Each batch in the CIFAR-10 dataset has randomly picked images, so the images come pre-shuffled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1521406510709,
     "user": {
      "displayName": "Ankur Kothari",
      "photoUrl": "//lh5.googleusercontent.com/-Lskyz0lrQRk/AAAAAAAAAAI/AAAAAAAACaI/etLcVFjKyHk/s50-c-k-no/photo.jpg",
      "userId": "111542912336803354359"
     },
     "user_tz": 240
    },
    "id": "TYjBXqxAj1Pj",
    "outputId": "0d8585e3-ce5e-42b2-9204-2d75551c681f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2VeNufCj1Po"
   },
   "source": [
    "### Access the *test* data and the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1521406511486,
     "user": {
      "displayName": "Ankur Kothari",
      "photoUrl": "//lh5.googleusercontent.com/-Lskyz0lrQRk/AAAAAAAAAAI/AAAAAAAACaI/etLcVFjKyHk/s50-c-k-no/photo.jpg",
      "userId": "111542912336803354359"
     },
     "user_tz": 240
    },
    "id": "XiJJ3zg9j1Pp",
    "outputId": "0246594c-817d-4d35-f5f4-a23a33323598"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ipxn6yQJj1Pv"
   },
   "source": [
    "### The CIFAR-10 dataset has color images\n",
    "\n",
    "* Each image is of size 32x32\n",
    "* The image is RGB so has 3 channels, and requires 3 numbers to represent each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "XaWN6ABBj1Pw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9lDE6riSj1Pz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnpEhoLLj1P2"
   },
   "source": [
    "### Placeholders for training data and labels\n",
    "\n",
    "* The training dataset placeholder can have any number of instances and each instance is an array of 32x32 pixels (we've already reshaped the data earlier)\n",
    "* The images are fed to the convolutional layer as a 4D tensor *[batch_size, height, width, channels]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ZotOozA0j1P3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hY2_QbDhj1P7"
   },
   "source": [
    "### Add a dropout layer to avoid overfitting the training data\n",
    "\n",
    "* The training flag is set to False during prediction and is True while training (dropout is applied only in the training phase)\n",
    "* The dropout_rate indicates the chances that a neuron is turned off during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Syyll83zj1P7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "fSFgw5xDj1P_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "maAW2PO9j1QC"
   },
   "source": [
    "### Neural network design\n",
    "\n",
    "* 2 convolutional layers\n",
    "* 1 max pooling layer\n",
    "* 1 convolutional layer\n",
    "* 1 max pooling layer\n",
    "* 2 fully connected layers\n",
    "* Output logits layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UjYrY32Jj1QD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Rf8ohHNEj1QF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vIYU-i3Yj1QJ"
   },
   "source": [
    "### Pooling reduces the size of the image\n",
    "\n",
    "The pooled image is only 1/4th the size of the original image with this kernel size and stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ysd-bh_uj1QK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qiWriLD9j1QO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nk8F67opj1QU"
   },
   "source": [
    "### Reshape the pooled layer to be a 1-D vector (flatten it) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "FLxtaKENj1QW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "-GlvZHRDj1Qb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Il4xC7h1j1Qg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xem7yKoYj1Qj"
   },
   "source": [
    "### There are 10 possible classifications in the CIFAR-10 dataset\n",
    "\n",
    "The number of outputs of the logits layer should be 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "KehwwYoej1Qk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18T_rWL_j1Qn"
   },
   "source": [
    "### The final output layer with softmax activation\n",
    "\n",
    "The *tf.nn.sparse_softmax_cross_entropy_with_logits* will apply the softmax activation as well as calculate the cross-entropy as our cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X):\n",
    "  \n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=X_drop,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"valid\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  conv2 = tf.layers.conv2d(conv1, filters=64, \n",
    "                       kernel_size=3,\n",
    "                       strides=2, padding=\"valid\",\n",
    "                       activation=tf.nn.relu, name=\"conv2\")\n",
    "  pool3 = tf.nn.max_pool(conv2,\n",
    "                     ksize=[1, 2, 2, 1],\n",
    "                     strides=[1, 2, 2, 1],\n",
    "                     padding=\"VALID\")\n",
    "  conv4 = tf.layers.conv2d(pool3, filters=128, \n",
    "                       kernel_size=4,\n",
    "                       strides=3, padding=\"SAME\",\n",
    "                       activation=tf.nn.relu, name=\"conv4\")\n",
    "\n",
    "  pool5 = tf.nn.max_pool(conv4,\n",
    "                     ksize=[1, 2, 2, 1],\n",
    "                     strides=[1, 1, 1, 1],\n",
    "                     padding=\"VALID\")\n",
    "\n",
    "  pool5_flat = tf.contrib.layers.flatten(pool5)\n",
    "\n",
    "  fullyconn1 = tf.layers.dense(pool5_flat, 128,\n",
    "                           activation=tf.nn.relu, name=\"fc1\")\n",
    "\n",
    "  fullyconn2 = tf.layers.dense(fullyconn1, 64,\n",
    "                           activation=tf.nn.relu, name=\"fc2\")\n",
    "  logits = tf.layers.dense(fullyconn2, 10, name=\"output\")\n",
    "  return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "2D1avJ2Zj1Qp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exZMXSddj1Qt"
   },
   "source": [
    "### Check correctness and accuracy of the prediction\n",
    "\n",
    "* Check whether the highest probability output in logits is equal to the y-label\n",
    "* Check the accuracy across all predictions (How many predictions did we get right?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qkFw1MaYj1Qu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "FLDEGkctj1Qw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BzeFTBh3j1Q0"
   },
   "source": [
    "### Set up a helper method to access training data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "bQwiwYK5j1Q1"
   },
   "outputs": [],
   "source": [
    "def get_next_batch(features, labels, train_size, batch_index, batch_size):\n",
    "    training_images = features[:train_size,:,:]\n",
    "    training_labels = labels[:train_size]\n",
    "    \n",
    "    start_index = batch_index * batch_size\n",
    "    end_index = start_index + batch_size\n",
    "\n",
    "    return features[start_index:end_index,:,:], labels[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1521406533387,
     "user": {
      "displayName": "Ankur Kothari",
      "photoUrl": "//lh5.googleusercontent.com/-Lskyz0lrQRk/AAAAAAAAAAI/AAAAAAAACaI/etLcVFjKyHk/s50-c-k-no/photo.jpg",
      "userId": "111542912336803354359"
     },
     "user_tz": 240
    },
    "id": "UyD3V_w4tRD_",
    "outputId": "c7627867-3074-4b0e-ad2c-ab51df9c2a2e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EDQkcjJWj1Q4"
   },
   "source": [
    "### Train and evaluate the model\n",
    "\n",
    "* For smaller training data you'll find that the model performs poorly, it improves as you increase the size of the training data (use all batches)\n",
    "* Ensure that dropout is enabled during training to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 490,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 336,
     "status": "error",
     "timestamp": 1521407245954,
     "user": {
      "displayName": "Ankur Kothari",
      "photoUrl": "//lh5.googleusercontent.com/-Lskyz0lrQRk/AAAAAAAAAAI/AAAAAAAACaI/etLcVFjKyHk/s50-c-k-no/photo.jpg",
      "userId": "111542912336803354359"
     },
     "user_tz": 240
    },
    "id": "3mYUwYg3j1Q5",
    "outputId": "d1b6597e-2fee-45f6-96fc-2332c817c68a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 609,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 339,
     "status": "error",
     "timestamp": 1521468770717,
     "user": {
      "displayName": "Ankur Kothari",
      "photoUrl": "//lh5.googleusercontent.com/-Lskyz0lrQRk/AAAAAAAAAAI/AAAAAAAACaI/etLcVFjKyHk/s50-c-k-no/photo.jpg",
      "userId": "111542912336803354359"
     },
     "user_tz": 240
    },
    "id": "Vac5JvfozZfT",
    "outputId": "c909fdd5-e289-4f41-efb9-b34f11950c03"
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈2 lines)\n",
    "    X = tf.placeholder(shape=[None, n_H0, n_W0, n_C0], dtype=\"float\", name=\"X\")\n",
    "    \n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 385,
     "status": "error",
     "timestamp": 1521405012407,
     "user": {
      "displayName": "Ankur Kothari",
      "photoUrl": "//lh5.googleusercontent.com/-Lskyz0lrQRk/AAAAAAAAAAI/AAAAAAAACaI/etLcVFjKyHk/s50-c-k-no/photo.jpg",
      "userId": "111542912336803354359"
     },
     "user_tz": 240
    },
    "id": "KNy7f_W0j1Q-",
    "outputId": "28ad1a2d-cb10-43ee-edc8-da721ac3f6c2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "def model(feature, labels, test_images, test_labels, learning_rate = 0.09,\n",
    "          n_epochs = 20, batch_size = 128, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = feature.shape             \n",
    "    X, y = create_placeholders(n_H0, n_W0, n_C0)\n",
    "    dropout_rate = 0.3\n",
    "\n",
    "    training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "    X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "    logits = forward_propagation(X_drop)\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                          labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "    #         batch_index = 0\n",
    "            # Add this in when we want to run the training on all batches in CIFAR-10\n",
    "            batch_index = 0\n",
    "\n",
    "            train_size = int(len(features))\n",
    "\n",
    "            for iteration in range(train_size // batch_size):\n",
    "                X_batch, y_batch = get_next_batch(features, \n",
    "                                                                            labels, \n",
    "                                                                            train_size, \n",
    "                                                                            batch_index,\n",
    "                                                                            batch_size)\n",
    "                batch_index += 1\n",
    "\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "\n",
    "            acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_test = accuracy.eval(feed_dict={X: test_images, y: test_labels})\n",
    "            print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "            print (\"Train Accuracy:\", round(acc_train, 2)*100,\"%\",  end=\"\\t\")\n",
    "            print (\"Test Accuracy:\", round(acc_test, 2)*100,\"%\", end=\"\\n\")\n",
    "            save_path = saver.save(sess, \"./cifar_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RaLykDVxj1RC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.5546875 Test accuracy: 0.4739\n",
      "Train Accuracy: 55.000001192092896 %\tTest Accuracy: 46.99999988079071 %\n"
     ]
    }
   ],
   "source": [
    "parameters = model(features, labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eUNmbk0Tj1RE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "YgPJ0iTjj1RJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "CNN_ImageClassification_CIFAR.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
